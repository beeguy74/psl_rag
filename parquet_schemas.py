"""
Parquet File Schema Definitions for PSL RAG Project

This module defines the structure of parquet files used in the PSL RAG project,
including both original processed files and the result files generated by the
summarization script (mattia-gemini.py).

Based on analysis of files in data/processed_parquets/
"""

from typing import Dict, Any, Optional, Union
from dataclasses import dataclass
from pathlib import Path
import pandas as pd


# =============================================================================
# TYPE DEFINITIONS
# =============================================================================

@dataclass
class PSLDocumentRecord:
    """
    Represents a single document record in the PSL RAG parquet files.
    
    This is the schema for all parquet files in data/processed_parquets/
    """
    source_file: str              # Path to original JSON file (e.g., "/Users/mattia/Desktop/PSL/DATA/MASTERS/MASTER FINANCE/MASTER FINANCE.json")
    text: str                     # Markdown-formatted content extracted from JSON
    word_count: int               # Number of words in the text content
    embedding_summary: str        # AI-generated summary for embeddings (empty string if not processed yet)


@dataclass 
class ParquetFileMetadata:
    """Metadata about a parquet file"""
    file_path: str
    total_documents: int
    memory_usage_mb: float
    columns: list[str]
    has_summaries: bool
    empty_summaries: int
    error_summaries: int


# =============================================================================
# SCHEMA DICTIONARIES
# =============================================================================

# PyArrow Schema (as would appear in pyarrow.Schema)
PYARROW_SCHEMA = {
    "source_file": "string (nullable: True)",
    "text": "string (nullable: True)", 
    "word_count": "int64 (nullable: True)",
    "embedding_summary": "string (nullable: True)"
}

# Pandas DataFrame dtypes
PANDAS_DTYPES = {
    "source_file": "object",
    "text": "object",
    "word_count": "int64", 
    "embedding_summary": "object"
}

# Column descriptions and constraints
COLUMN_SPECIFICATIONS = {
    "source_file": {
        "description": "Absolute path to the original JSON file from which this document was extracted",
        "data_type": "string",
        "nullable": False,
        "typical_length_range": (70, 320),
        "example": "/Users/mattia/Desktop/PSL/DATA/MASTERS/MASTER FINANCE/MASTER FINANCE.json",
        "pattern": "Ends with either '.json' (main program) or 'Parcours *.json' (academic track)"
    },
    "text": {
        "description": "Markdown-formatted content extracted and processed from the original JSON",
        "data_type": "string", 
        "nullable": False,
        "typical_length_range": (1700, 21400),
        "typical_word_count_range": (278, 3342),
        "format": "Markdown with headers (# Formation, ## Langue Id, etc.)",
        "content": "Contains program info, admission requirements, curriculum details, etc."
    },
    "word_count": {
        "description": "Number of words in the text content",
        "data_type": "int64",
        "nullable": False,
        "typical_range": (278, 3342),
        "calculation": "Calculated from 'text' field word count"
    },
    "embedding_summary": {
        "description": "AI-generated concise summary optimized for embedding generation and semantic search",
        "data_type": "string",
        "nullable": False,  # Always present but may be empty
        "typical_length_range": (0, 950),  # 0 when empty, 400-950 when populated
        "states": {
            "empty": "Empty string '' - not yet processed",
            "valid": "2-4 sentence summary suitable for embeddings",
            "error": "Starts with '[SUMMARY_ERROR:' or '[EMPTY_TEXT]'"
        }
    }
}


# =============================================================================
# FILE STRUCTURE INFORMATION 
# =============================================================================

PROCESSED_PARQUET_FILES = {
    "masters_data.parquet": {
        "description": "Master's degree programs from PSL universities",
        "typical_documents": 334,
        "typical_memory_mb": 5.2,
        "source_directory": "MASTERS/",
        "includes_parcours": True
    },
    "licences_data.parquet": {
        "description": "Bachelor's degree programs (Licence level)",
        "typical_documents": 68,
        "typical_memory_mb": 1.2,
        "source_directory": "LICENCES/",
        "includes_parcours": True
    },
    "doctorats_data.parquet": {
        "description": "Doctoral programs (PhD level)",
        "typical_documents": 25,
        "typical_memory_mb": 0.16,
        "source_directory": "DOCTORATS/",
        "includes_parcours": True
    },
    "diplomes_etablissements_composantes_data.parquet": {
        "description": "Institution-specific diplomas and specialized programs",
        "typical_documents": 49,
        "typical_memory_mb": 0.68,
        "source_directory": "DIPLOMES_ETABLISSEMENTS_COMPOSANTES/",
        "includes_parcours": True
    }
}

# Files generated by the summarization script
TEMP_FILES_PATTERN = "temp_summarization_{original_filename}"


# =============================================================================
# CONTENT STRUCTURE EXAMPLES
# =============================================================================

MARKDOWN_TEXT_STRUCTURE = """
# Formation
# Niveau Diplome Id
{diploma_level_id}

# Diplome Delivre  
{diploma_name}

# Niveau Sortie Id
{output_level_id}

# Domaines
- {domain_ids}

# Etablissements Operateurs
- {operating_institutions}

# Etablissements Engages
- {engaged_institutions}

# Type Formation
- {formation_type_ids}

# Langue Enseignement
- {teaching_language_ids}

# Responsables Formation
- {responsible_persons}

# Disciplines
- {discipline_ids}

# Detail Formation
## Langue Id
{language_id}

## Nom
{program_name}

## Presentation
{program_description}

## Objectifs
{program_objectives}

## Conditions Acces
{access_conditions}

## Modalites Controle Connaissances
{assessment_methods}

## Poursuite Etudes
{further_studies}

## Debouches Professionnels
{career_prospects}

[... additional sections as available ...]
"""


SOURCE_FILE_PATTERNS = {
    "main_program": {
        "pattern": "*/PROGRAM_NAME/PROGRAM_NAME.json",
        "example": "/Users/mattia/Desktop/PSL/DATA/MASTERS/MASTER FINANCE/MASTER FINANCE.json",
        "description": "Main program information file"
    },
    "academic_track": {
        "pattern": "*/PROGRAM_NAME/PARCOURS/PROGRAM_NAME_Parcours_TRACK_NAME.json",
        "example": "/Users/mattia/Desktop/PSL/DATA/MASTERS/MASTER FINANCE/PARCOURS/MASTER FINANCE_Parcours Audit and financial advisory (M2).json",
        "description": "Specific academic track/specialization within a program"
    }
}


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def validate_document_record(record: Dict[str, Any]) -> tuple[bool, list[str]]:
    """
    Validate that a document record conforms to the expected schema.
    
    Args:
        record: Dictionary representing a document record
        
    Returns:
        Tuple of (is_valid, list_of_errors)
    """
    errors = []
    
    # Check required fields
    required_fields = ["source_file", "text", "word_count", "embedding_summary"]
    for field in required_fields:
        if field not in record:
            errors.append(f"Missing required field: {field}")
    
    # Type checks
    if "source_file" in record and not isinstance(record["source_file"], str):
        errors.append("source_file must be a string")
    
    if "text" in record and not isinstance(record["text"], str):
        errors.append("text must be a string")
    
    if "word_count" in record and not isinstance(record["word_count"], int):
        errors.append("word_count must be an integer")
    
    if "embedding_summary" in record and not isinstance(record["embedding_summary"], str):
        errors.append("embedding_summary must be a string")
    
    # Content validation
    if "source_file" in record:
        if not record["source_file"].endswith(".json"):
            errors.append("source_file should end with '.json'")
    
    if "text" in record:
        if len(record["text"]) < 100:
            errors.append("text content seems too short (< 100 characters)")
    
    if "word_count" in record and "text" in record:
        # Rough word count validation (should be roughly similar)
        actual_words = len(record["text"].split())
        if abs(actual_words - record["word_count"]) > (actual_words * 0.3):  # 30% tolerance
            errors.append(f"word_count ({record['word_count']}) doesn't match actual word count (~{actual_words})")
    
    return len(errors) == 0, errors


def get_summary_status(embedding_summary: str) -> str:
    """
    Determine the status of an embedding summary.
    
    Args:
        embedding_summary: The summary string
        
    Returns:
        Status: "empty", "valid", "error"
    """
    if not embedding_summary or embedding_summary == "":
        return "empty"
    elif embedding_summary.startswith("["):
        return "error"
    else:
        return "valid"


def analyze_parquet_file(file_path: Union[str, Path]) -> ParquetFileMetadata:
    """
    Analyze a parquet file and return metadata.
    
    Args:
        file_path: Path to the parquet file
        
    Returns:
        ParquetFileMetadata object with analysis results
    """
    df = pd.read_parquet(file_path)
    
    # Count summary states
    empty_summaries = (df['embedding_summary'] == '').sum()
    error_summaries = df['embedding_summary'].str.startswith('[', na=False).sum()
    
    return ParquetFileMetadata(
        file_path=str(file_path),
        total_documents=len(df),
        memory_usage_mb=df.memory_usage(deep=True).sum() / (1024 * 1024),
        columns=list(df.columns),
        has_summaries=(empty_summaries < len(df)),
        empty_summaries=empty_summaries,
        error_summaries=error_summaries
    )


# =============================================================================
# EXAMPLE DATA
# =============================================================================

EXAMPLE_DOCUMENT_RECORD = PSLDocumentRecord(
    source_file="/Users/mattia/Desktop/PSL/DATA/MASTERS/MASTER FINANCE/MASTER FINANCE.json",
    text="""# Formation
# Niveau Diplome Id
2

# Diplome Delivre
Diplôme d'établissement conférant grade de master

# Niveau Sortie Id
6

# Domaines
- 2
- 4

# Etablissements Operateurs
- Dauphine - PSL

# Detail Formation
## Langue Id
1

## Nom
MASTER FINANCE

## Presentation
Le master Finance forme des cadres financiers de haut niveau pour les entreprises et pour les institutions financières...""",
    word_count=436,
    embedding_summary="The MASTER FINANCE program at Dauphine - PSL delivers a Master's degree, forming high-level financial executives for companies and financial institutions with deep technical skills, management capabilities, and research-oriented knowledge through excellence training in the French university landscape."
)


if __name__ == "__main__":
    # Example usage
    print("PSL RAG Parquet Schema Definitions")
    print("=" * 50)
    
    print("\nSchema Overview:")
    for col, spec in COLUMN_SPECIFICATIONS.items():
        print(f"  {col}: {spec['description']}")
    
    print(f"\nExample record validation:")
    record_dict = {
        "source_file": EXAMPLE_DOCUMENT_RECORD.source_file,
        "text": EXAMPLE_DOCUMENT_RECORD.text,
        "word_count": EXAMPLE_DOCUMENT_RECORD.word_count,
        "embedding_summary": EXAMPLE_DOCUMENT_RECORD.embedding_summary
    }
    is_valid, errors = validate_document_record(record_dict)
    print(f"  Valid: {is_valid}")
    if errors:
        print(f"  Errors: {errors}")